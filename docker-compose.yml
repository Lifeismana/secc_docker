services:
  traefik:
    image: docker.io/library/traefik:v3.4
    container_name: traefik
    env_file:
      - env/traefik.env
    environment:
      - TZ=Europe/Paris
      - NAS_NAME=${MAIN_NAS}
    networks:
      net-proxy:
        ipv4_address: 172.25.0.254
      net-prometheus:
      net-redis:
    healthcheck:
      test: [ "CMD", "traefik", "healthcheck", "--ping" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    ports:
      - '80:80'
      - '443:443'
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /data/traefik:/data
      - /home/cert-syno/cert:/syno:ro,uid=1001,gid=1001
      - ./traefik/traefik_dynamic.yaml:/etc/traefik/traefik_dynamic.yaml
      - logs-traefik:/var/log/traefik
    command:
      - "--api.dashboard=true"
      - "--metrics.prometheus=true"
      - "--ping=true"
      - "--log.level=INFO"
      - "--providers.docker=true"
      - "--providers.docker.network=net-proxy"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.file.filename=/etc/traefik/traefik_dynamic.yaml"
      - "--accesslog"
      - "--accesslog.filepath=/var/log/traefik/access.log"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.web.http.redirections.entryPoint.to=websecure"
      - "--entrypoints.web.http.redirections.entryPoint.scheme=https"
      - "--entrypoints.web.http.redirections.entryPoint.permanent=true"
      - "--entrypoints.websecure.address=:443"
      # trust Cloudflare IPs
      - "--entrypoints.websecure.forwardedHeaders.trustedIPs=173.245.48.0/20,103.21.244.0/22,103.22.200.0/22,103.31.4.0/22,141.101.64.0/18,108.162.192.0/18,190.93.240.0/20,188.114.96.0/20,197.234.240.0/22,198.41.128.0/17,162.158.0.0/15,104.16.0.0/13,104.24.0.0/14,172.64.0.0/13,131.0.72.0/22,2400:cb00::/32,2606:4700::/32,2803:f800::/32,2405:b500::/32,2405:8100::/32,2a06:98c0::/29,2c0f:f248::/32"
      - "--entrypoints.websecure.http.tls.certresolver=cloudflare_main"
      - "--entrypoints.websecure.http.tls.domains[0].main=${MAIN_DOMAIN}"
      - "--entrypoints.websecure.http.tls.domains[0].sans=*.${MAIN_DOMAIN}"
      - "--entrypoints.websecure.http.tls.domains[1].main=*.internal.${MAIN_DOMAIN}"
      - "--entrypoints.websecure.http.tls.domains[2].main=${SECONDARY_DOMAIN}"
      - "--entrypoints.websecure.http.tls.domains[2].sans=*.${SECONDARY_DOMAIN}"
      - "--certificatesResolvers.cloudflare_main.acme.email=${CLOUDFLARE_EMAIL}"
      - "--certificatesResolvers.cloudflare_main.acme.storage=/data/acme/acme.json"
      - "--certificatesResolvers.cloudflare_main.acme.dnsChallenge.provider=cloudflare"
      - "--certificatesResolvers.cloudflare_main.acme.dnsChallenge.propagation.delayBeforeChecks=120"
      # crowdsec plugin
      - "--experimental.plugins.crowdsec.modulename=github.com/maxlerebourg/crowdsec-bouncer-traefik-plugin"
      - "--experimental.plugins.crowdsec.version=v1.4.2"
    labels:
      - "traefik.enable=true"
      - "traefik.http.services.justAdummyService.loadbalancer.server.port=1337"
      - "traefik.http.routers.traefik.rule=Host(`traefik.internal.${MAIN_DOMAIN}`) && (PathPrefix(`/api`) || PathPrefix(`/dashboard`))"
      - "traefik.http.routers.traefik.entrypoints=websecure"
      - "traefik.http.routers.traefik.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.traefik.tls.domains[0].main=internal.${MAIN_DOMAIN}"
      - "traefik.http.routers.traefik.tls.domains[0].sans=*.internal.${MAIN_DOMAIN}"
      - "traefik.http.routers.traefik.service=api@internal"
      - "traefik.http.routers.traefik.middlewares=tailscaleAL"
      - "traefik.http.routers.github-redirect.rule=Host(`$SECONDARY_DOMAIN`) && PathRegexp(`^/?$`)"
      - "traefik.http.routers.github-redirect.entrypoints=websecure"
      - "traefik.http.routers.github-redirect.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.github-redirect.priority=50000"
      - "traefik.http.routers.github-redirect.middlewares=github-redirect"
      - "traefik.http.middlewares.github-redirect.redirectregex.regex=.*"
      - "traefik.http.middlewares.github-redirect.redirectregex.replacement=https://github.com/Lifeismana"
      - "traefik.http.middlewares.github-redirect.redirectregex.permanent=false"
      - "traefik.http.middlewares.tailscaleAL.ipAllowList.sourcerange=100.64.0.0/10, fd7a:115c:a1e0::/96, 172.16.0.0/12"
      - "traefik.http.middlewares.crowdsec.plugin.crowdsec.enabled=true"
      - "traefik.http.middlewares.crowdsec.plugin.crowdsec.crowdsecmode=stream"
      - "traefik.http.middlewares.crowdsec.plugin.crowdsec.forwardedheaderstrustedips=173.245.48.0/20,103.21.244.0/22,103.22.200.0/22,103.31.4.0/22,141.101.64.0/18,108.162.192.0/18,190.93.240.0/20,188.114.96.0/20,197.234.240.0/22,198.41.128.0/17,162.158.0.0/15,104.16.0.0/13,104.24.0.0/14,172.64.0.0/13,131.0.72.0/22,2400:cb00::/32,2606:4700::/32,2803:f800::/32,2405:b500::/32,2405:8100::/32,2a06:98c0::/29,2c0f:f248::/32"
      - "traefik.http.middlewares.crowdsec.plugin.crowdsec.crowdsecAppsecEnabled=true"
      - "traefik.http.middlewares.crowdsec.plugin.crowdsec.crowdsecLapiKey=${CROWDSEC_LAPI_KEY}"
      - "traefik.http.middlewares.crowdsec.plugin.crowdsec.crowdsecappsechost=crowdsec:7422"
      - "traefik.http.middlewares.crowdsec.plugin.crowdsec.rediscacheenabled=true"
      - "traefik.http.middlewares.crowdsec.plugin.crowdsec.rediscachehost=redis:6379"
      - homepage.group=Main
      - homepage.name=Traefik
      - homepage.icon=traefik.png
      - homepage.href=https://traefik.internal.${MAIN_DOMAIN}
      - homepage.description=Traefik
      - homepage.widget.type=traefik
      - homepage.widget.url=https://traefik.internal.${MAIN_DOMAIN}
      - wud.tag.include=^v\d+\.\d+$
    restart: unless-stopped

  logrotate:
    container_name: traefik-logrotate
    image: vegardit/traefik-logrotate:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:rw # required to send USR1 signal to Traefik after log rotation
      - logs-traefik:/var/log/traefik:rw
    network_mode: none
    environment:
      TZ: "Europe/Paris"
      CRON_SCHEDULE: "0 * * * *"

  homepage:
    image: ghcr.io/gethomepage/homepage:v1.2
    container_name: homepage
    environment:
      - HOMEPAGE_ALLOWED_HOSTS=home.${MAIN_DOMAIN}
    volumes:
      - /data/homepage:/app/config
      - /var/run/docker.sock:/var/run/docker.sock:ro
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.homepage.rule=Host(`home.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.homepage.entrypoints=websecure"
      - "traefik.http.routers.homepage.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.homepage.middlewares=forwardAuth-authentik,crowdsec"
    restart: unless-stopped
    networks:
      - net-proxy

  portainer:
    container_name: portainer
    image: portainer/portainer-ce:windowsltsc2022-amd64-2.9.3
    restart: unless-stopped
    #ports:
    #  - '9000:9000'
    volumes:
      - /data/portainer:/data:uid=1000,gid=994
    networks:
      - net-proxy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.portainer.rule=Host(`portainer.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.portainer.entrypoints=websecure"
      - "traefik.http.routers.portainer.tls.certresolver=cloudflare_main"
      - "traefik.http.services.portainer.loadbalancer.server.port=9000"
      - "traefik.http.routers.portainer.middlewares=tailscaleAL"
      - homepage.group=Main
      - homepage.name=Portainer
      - homepage.icon=portainer.png
      - homepage.description=Portainer
      - homepage.href=https://portainer.internal.${MAIN_DOMAIN}
      - homepage.widget.type=portainer
      - homepage.widget.url=https://portainer.internal.${MAIN_DOMAIN}
      - homepage.widget.env=3
      - homepage.widget.key=${PORTAINER_TOKEN}

  speedtest-tracker:
    container_name: speedtest-tracker
    image: lscr.io/linuxserver/speedtest-tracker:latest
    restart: unless-stopped
    volumes:
      - /data/speedtest-tracker:/config
    env_file:
      - env/speedtest-tracker.env
    environment:
      - TZ=Europe/Paris
      - DISPLAY_TIMEZONE=Europe/Paris
      - PUID=1000
      - PGID=994
      - DB_CONNECTION=pgsql
      - DB_HOST=postgres
      - DB_DATABASE=speedtest_trackerdb
      - DB_USERNAME=speedtest_tracker
      - SPEEDTEST_SCHEDULE="10 */2 * * *"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.speedtest-tracker.rule=Host(`speedtest-tracker.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.speedtest-tracker.entrypoints=websecure"
      - "traefik.http.routers.speedtest-tracker.tls.certresolver=cloudflare_main"
      - "traefik.http.services.speedtest-tracker.loadbalancer.server.port=80"
      - "traefik.http.routers.speedtest-tracker.middlewares=tailscaleAL"
      - homepage.group=Main
      - homepage.name=Speedtest Tracker
      - homepage.icon=librespeed.png
      - homepage.description=Speedtest Tracker
      - homepage.href=https://speedtest-tracker.internal.${MAIN_DOMAIN}
      - homepage.widget.type=speedtest
      - homepage.widget.url=https://speedtest-tracker.internal.${MAIN_DOMAIN}
    networks:
      - net-proxy
      - net-postgres

  netalertx:
    container_name: NetAlertX
    hostname: NetAlertX
    privileged: true
    image: ghcr.io/jokob-sk/netalertx:latest
    environment:
      - TZ=Europe/Paris
      # listen only on the network traefik is to not get blocked by firewalld 
      # (might become a problem if we're "unlucky" and this isn't the subnet that gets assigned)
      - LISTEN_ADDR=172.17.0.1
    restart: unless-stopped
    volumes:
      - /data/netalertx/db:/app/db
      - /data/netalertx/config:/app/config
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.netalertx.rule=Host(`netalertx.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.netalertx.entrypoints=websecure"
      - "traefik.http.routers.netalertx.tls.certresolver=cloudflare_main"
      - "traefik.http.services.netalertx.loadbalancer.server.port=20211"
      - "traefik.http.routers.netalertx.middlewares=tailscaleAL"
      - homepage.group=Main
      - homepage.name=NetAlertX
      - homepage.icon=netalertx.png
      - homepage.description=NetAlertX
      - homepage.href=https://netalertx.internal.${MAIN_DOMAIN}
      - homepage.widget.type=netalertx
      - homepage.widget.url=https://netalertx.internal.${MAIN_DOMAIN}
    network_mode: host

  glances:
    image: nicolargo/glances:4.3.1
    container_name: glances
    restart: unless-stopped
    pid: host
    privileged: true
    network_mode: "host"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:61208/api/4/status" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    environment:
      - TZ=Europe/Paris
      - GLANCES_OPT=-w
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.glances.rule=Host(`glances.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.glances.entrypoints=websecure"
      - "traefik.http.routers.glances.tls.certresolver=cloudflare_main"
      - "traefik.http.services.glances.loadbalancer.server.port=61208"
      - "traefik.http.routers.glances.middlewares=tailscaleAL"
      - homepage.group=Main
      - homepage.name=Glances
      - homepage.icon=glances.png
      - homepage.description=Glances
      - homepage.href=https://glances.internal.${MAIN_DOMAIN}
      - homepage.widget.type=glances
      - homepage.widget.url=https://glances.internal.${MAIN_DOMAIN}
      - homepage.widget.version=4
      - homepage.widget.metric=info #,cpu,memory,process

  beszel:
    container_name: beszel
    image: ghcr.io/henrygd/beszel/beszel:0.11.1
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "/beszel", "health", '--url', 'http://localhost:8090' ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 5s
    environment:
      - DISABLE_PASSWORD_AUTH=true
      - USER_CREATION=true
    networks:
      - net-proxy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - /data/beszel:/beszel_data
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.beszel.rule=Host(`beszel.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.beszel.entrypoints=websecure"
      - "traefik.http.routers.beszel.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.beszel.middlewares=tailscaleAL"

  beszel-agent:
    container_name: beszel-agent
    image: ghcr.io/henrygd/beszel/beszel-agent:0.11.1
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "/agent", "health" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 5s
    network_mode: "host"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /.beszel:/extra-filesystems/disk1:ro
      - /data_alt/.beszel:/extra-filesystems/disk2:ro
      - /data/.beszel:/extra-filesystems/disk3:ro
      - /docker_data/.beszel:/extra-filesystems/disk4:ro
    environment:
      - LISTEN=45876
    env_file:
      - env/beszel-agent.env

  dozzle:
    container_name: dozzle
    image: amir20/dozzle:v8
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "/dozzle", "healthcheck" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - net-proxy
    environment:
      - TZ=Europe/Paris
      - DOZZLE_AUTH_PROVIDER=forward-proxy
      - DOZZLE_ENABLE_SHELL=true
      - DOZZLE_AUTH_HEADER_USER=X-authentik-username
      - DOZZLE_AUTH_HEADER_EMAIL=X-authentik-email
      - DOZZLE_AUTH_HEADER_NAME=X-authentik-name
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.dozzle.rule=Host(`dozzle.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.dozzle.entrypoints=websecure"
      - "traefik.http.routers.dozzle.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.dozzle.middlewares=tailscaleAL,forwardAuth-authentik"

  endlessh:
    container_name: endlessh
    #? maybe use a fixed version instead of latest but version scheme is horrible
    image: shizunge/endlessh-go:latest
    command:
      - "-logtostderr"
      - "-v=1"
      - "-geoip_supplier=max-mind-db"
      - "-max_mind_db=/geo-data/GeoLite2-City.mmdb"
      - "-enable_prometheus"
    ports:
      # TODO: change 222 to 22 when i'll have changed the ssh port on the server
      - '222:222'
    volumes:
      - geoip:/geo-data/:ro
    restart: unless-stopped
    networks:
      - net-proxy
      - net-prometheus

  portainer_agent:
    container_name: portainer_agent
    image: portainer/agent:2.29.2
    restart: unless-stopped
    #ports:
    #  - 9001:9001
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /docker_data/volumes:/var/lib/docker/volumes
    networks:
      - net-proxy

  watchtower:
    container_name: watchtower
    image: ghcr.io/nicholas-fedor/watchtower:1.9.1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      TZ: Europe/Paris
      WATCHTOWER_CLEANUP: true
      DOCKER_API_VERSION: 1.49
      WATCHTOWER_SCHEDULE: 0 0 5 * * *
      WATCHTOWER_TIMEOUT: 5m
      WATCHTOWER_HTTP_API_METRICS: true
      WATCHTOWER_HTTP_API_TOKEN: ${WATCHTOWER_TOKEN}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.watchtower.rule=Host(`watchtower.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.watchtower.entrypoints=websecure"
      - "traefik.http.routers.watchtower.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.watchtower.middlewares=tailscaleAL"
      - homepage.group=Main
      - homepage.name=Watchtower
      - homepage.icon=watchtower.png
      - homepage.description=Watchtower
      - homepage.widget.type=watchtower
      - homepage.widget.url=https://watchtower.internal.${MAIN_DOMAIN}
      - homepage.widget.key=${WATCHTOWER_TOKEN}
    restart: unless-stopped
    networks:
      - net-proxy

  whatsupdocker:
    image: getwud/wud:8.0.1
    container_name: whatsupdocker
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - whatsupdocker:/store
      - ./wud/webhook-update.sh:/wud/webhook-update.sh:ro
    healthcheck:
      test: curl --fail http://localhost:3000/health || exit 1 && curl http://localhost:3000/auth/strategies | jq -e '. | length > 0' || exit 1
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 10s
    env_file:
      - env/whats-up-docker.env
    environment:
      - TZ=Europe/Paris
      - WUD_WATCHER_LOCAL_CRON=0 5 * * *
      - WUD_WATCHER_LOCAL_WATCHALL=true
      - WUD_AUTH_OIDC_AUTHENTIK_REDIRECT=true
      - WUD_TRIGGER_COMMAND_TAGUPDATE_CMD=/wud/webhook-update.sh
      - WUD_TRIGGER_COMMAND_TAGUPDATE_AUTO=true
    networks:
      - net-proxy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.whatsupdocker.rule=Host(`whatsupdocker.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.whatsupdocker.entrypoints=websecure"
      - "traefik.http.routers.whatsupdocker.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.whatsupdocker.middlewares=tailscaleAL"
    depends_on:
      traefik:
        condition: service_started
        restart: false
      authentik-server:
        condition: service_healthy
        restart: false

  cloudflare-ddns:
    image: timothyjmiller/cloudflare-ddns:latest
    container_name: cloudflare-ddns
    security_opt:
      - no-new-privileges:true
    network_mode: "host"
    environment:
      - PUID=1000
      - PGID=994
    volumes:
      - /data/cloudflareddns/config.json:/config.json
    restart: unless-stopped

  tailscale-cloudflare-dnssync:
    image: ghcr.io/lifeismana/tailscale-cloudflare-dnssync:main
    container_name: tailscale-cloudflare-dnssync
    env_file:
      - env/tailscale-cloudflare-dnssync.env
    environment:
      - PUID=1000
      - PGID=994
    restart: unless-stopped

  postgres-14:
    image: postgres:14
    container_name: postgres-14
    restart: unless-stopped
    env_file:
      - env/postgres-14.env
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready", "-U", "postgres" ]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 5s
    volumes:
      - /data_alt/postgres-14:/var/lib/postgresql/data
      - /var/run/postgresql:/var/run/postgresql
    network_mode: none
    labels:
      - wud.watch=false

  postgres:
    image: postgres:17
    container_name: postgres
    restart: unless-stopped
    env_file:
      - env/postgres.env
    # ports:
    #   - 127.0.0.1:5432:5432
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready", "-U", "postgres" ]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 5s
    volumes:
      - /data_alt/postgres:/var/lib/postgresql/data
    networks:
      - net-postgres
    labels:
      - wud.tag.include=^\d+$

  gitea:
    #TODO: change this once 1.24 is out (this is nightly rootless 1.24)
    image: gitea/gitea@sha256:009d2ff7f9b98bc00e54a1afcac630c66a4b2eb6a2783f514d2b2bd0cdbd3cfa
    container_name: gitea
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:3000/api/healthz" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    ports:
      - 22:22
    env_file:
      - env/gitea.env
    environment:
      - USER_UID=103
      - USER_GID=113
      - GITEA__SERVICE__DISABLE_REGISTRATION=false
      - GITEA__SERVICE__ENABLE_BASIC_AUTHENTICATION=false
      - GITEA__SERVICE__ENABLE_PASSWORD_SIGNIN_FORM=false
      - GITEA__SERVICE__ALLOW_ONLY_EXTERNAL_REGISTRATION=true
      - GITEA__OAUTH2_CLIENT__ENABLE_AUTO_REGISTRATION=true
      - GITEA__OPENID__ENABLE_OPENID_SIGNIN=false
      - GITEA__SERVER__DOMAIN=git.${MAIN_DOMAIN}
      - GITEA__SERVER__ROOT_URL=https://git.${MAIN_DOMAIN}/
      - GITEA__SERVER__LFS_START_SERVER=true
      - GITEA__DATABASE__DB_TYPE=postgres
      - GITEA__DATABASE__HOST=postgres:5432
      - GITEA__DATABASE__NAME=giteadb
      - GITEA__DATABASE__USER=gitea
      - GITEA__CACHE__ADAPTER=redis
      - GITEA__CACHE__HOST=redis://redis:6379/0?pool_size=100&idle_timeout=180s
      - GITEA__SESSION__PROVIDER=redis
      - GITEA__SESSION__PROVIDER_CONFIG=redis://redis:6379/0?pool_size=100&idle_timeout=180s
      - GITEA__SERVER__SSH_PORT=22
      - GITEA__SERVER__SSH_LISTEN_PORT=22
      - GITEA__SERVER__OFFLINE_MODE=false
    volumes:
      - /data_alt/gitea/data:/var/lib/gitea
      - /data_alt/gitea/config:/etc/gitea
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.gitea.rule=Host(`git.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.gitea.entrypoints=websecure"
      - "traefik.http.routers.gitea.tls.certresolver=cloudflare_main"
      - "traefik.http.services.gitea.loadbalancer.server.port=3000"
      - "traefik.http.routers.gitea.middlewares=crowdsec"
      - crowdsec.enable=true
      - crowdsec.labels.type=gitea
    networks:
      - net-proxy
      - net-postgres
      - net-redis
    depends_on:
      - postgres
      - redis

  redis:
    container_name: redis
    image: docker.io/library/redis:8-alpine
    command: --save 60 1 --loglevel warning
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "redis-cli ping | grep PONG" ]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 3s
    volumes:
      - /data_alt/redis:/data
    networks:
      - net-redis

  redis-exporter:
    container_name: redis-exporter
    image: ghcr.io/oliver006/redis_exporter:v1.71.0
    restart: unless-stopped
    environment:
      - REDIS_ADDR=redis:6379
      - REDIS_USER=null
    networks:
      - net-redis
      - net-prometheus

  # TODO: add thanos
  prometheus:
    container_name: prometheus
    image: quay.io/prometheus/prometheus:v3.3.1
    restart: unless-stopped
    healthcheck:
      # not sure why the /healthy endpoint is not working as doc mentions
      test: [ "CMD-SHELL", "wget -O - http://localhost:9090 &>/dev/null" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    user: 1000:1000
    volumes:
      - /data_alt/prometheus:/prometheus
      - ./prometheus/:/etc/prometheus/
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    networks:
      - net-proxy
      - net-prometheus
    extra_hosts:
      - "host.docker.internal:host-gateway"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.prometheus.rule=Host(`prometheus.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.prometheus.entrypoints=websecure"
      - "traefik.http.routers.prometheus.tls.certresolver=cloudflare_main"
      - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
      - "traefik.http.routers.prometheus.middlewares=tailscaleAL"
      - homepage.group=Main
      - homepage.name=Prometheus
      - homepage.icon=prometheus.png
      - homepage.description=Prometheus
      - homepage.href=https://prometheus.internal.${MAIN_DOMAIN}
      - homepage.widget.type=prometheus
      - homepage.widget.url=https://prometheus.internal.${MAIN_DOMAIN}

  influxdb:
    image: influxdb:2.2
    container_name: influxdb
    volumes:
      - '/data_alt/influxdb:/var/lib/influxdb2'
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8086/health" ]
      interval: 30s
      timeout: 5s
      retries: 5
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.influxdb.rule=Host(`influxdb.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.influxdb.entrypoints=websecure"
      - "traefik.http.routers.influxdb.tls.certresolver=cloudflare_main"
      - "traefik.http.services.influxdb.loadbalancer.server.port=8086"
      - "traefik.http.routers.influxdb.middlewares=tailscaleAL"
      - wud.tag.include=^\d+\.\d+$
    networks:
      - net-proxy
      - net-influxdb

  scrutiny-web:
    #TODO: use a fixed version once there's more recent release
    image: ghcr.io/analogj/scrutiny:master-web
    container_name: scrutiny-web
    volumes:
      - '/data/scrutiny:/opt/scrutiny/config'
    environment:
      - SCRUTINY_WEB_INFLUXDB_HOST=influxdb
      # - SCRUTINY_WEB_INFLUXDB_TOKEN=your-very-secret-token
      # - SCRUTINY_WEB_INFLUXDB_ORG=homelab
      # - SCRUTINY_WEB_INFLUXDB_BUCKET=scrutiny
      #TODO: add a notification system (maybe ?)
      #- SCRUTINY_NOTIFY_URLS=["http://gotify:80/message?token=a-gotify-token"]
    env_file:
      - env/scrutiny.env
    depends_on:
      influxdb:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/api/health" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 10s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.scrutiny.rule=Host(`scrutiny.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.scrutiny.entrypoints=websecure"
      - "traefik.http.routers.scrutiny.tls.certresolver=cloudflare_main"
      - "traefik.http.services.scrutiny.loadbalancer.server.port=8080"
      - "traefik.http.routers.scrutiny.middlewares=tailscaleAL"
      - homepage.group=Main
      - homepage.name=Scrutiny
      - homepage.icon=scrutiny.png
      - homepage.href=https://scrutiny.internal.${MAIN_DOMAIN}
      - homepage.description=Scrutiny
      - homepage.widget.type=scrutiny
      - homepage.widget.url=https://scrutiny.internal.${MAIN_DOMAIN}
    networks:
      - net-proxy
      - net-influxdb

  redbot:
    container_name: redbot
    image: ghcr.io/lifeismana/docker-red-discordbot:full
    restart: unless-stopped
    volumes:
      - /data_alt/redbot:/data
      - /data_alt/.ssh/red_github/:/config/.ssh/
      - /data_alt/.pylav-red/pylav.yaml:/config/pylav.yaml
      - /var/run/postgresql:/var/run/postgresql
      - /data_alt/.pylav-red/PyLav:/config/.config/PyLav
    environment:
      - CUSTOM_REDBOT_PACKAGE=git+https://github.com/Cog-Creators/Red-DiscordBot.git@V3/develop#egg=Red-DiscordBot
      - TZ=Europe/Paris
      - EXTRA_ARGS=--dev --rpc #--mentionable
    depends_on:
      - postgres-14
    networks:
      - net-proxy

  red-dashboard:
    container_name: red-dashboard
    image: ghcr.io/phasecorex/red-dashboard:latest
    restart: unless-stopped
    environment:
      - TZ=Europe/Paris
    volumes:
      - /data_alt/red-dashboard:/data
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.reddash.rule=Host(`red-dashboard.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.reddash.entrypoints=websecure"
      - "traefik.http.routers.reddash.tls.certresolver=cloudflare_main"
      - "traefik.http.services.reddash.loadbalancer.server.port=42356"
      - "traefik.http.routers.reddash.middlewares=crowdsec"
    network_mode: "service:redbot"
    depends_on:
      - redbot

  grafana:
    container_name: grafana
    image: grafana/grafana:12.0.0
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:3000/api/health" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ORG_NAME=Lifesismana
      - GF_RENDERING_SERVER_URL=http://renderer:8081/render
      - GF_RENDERING_CALLBACK_URL=http://localhost:3000/
      - GF_INSTALL_PLUGINS=marcusolsson-calendar-panel
    user: 1000:1000
    volumes:
      - /data/grafana:/var/lib/grafana
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.grafana.rule=Host(`grafana.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.grafana.entrypoints=websecure"
      - "traefik.http.routers.grafana.tls.certresolver=cloudflare_main"
      - "traefik.http.services.grafana.loadbalancer.server.port=3000"
      - "traefik.http.routers.grafana.middlewares=tailscaleAL"
      - homepage.group=Main
      - homepage.name=Grafana
      - homepage.icon=grafana.png
      - homepage.description=Grafana
      - homepage.widget.type=grafana
      - homepage.widget.url=https://grafana.internal.${MAIN_DOMAIN}
      - homepage.widget.username=${GRAFANA_USER}
      - homepage.widget.password=${GRAFANA_PASSWORD}
    networks:
      - net-proxy

  renderer:
    container_name: grafana-renderer
    image: grafana/grafana-image-renderer:3.12.5
    environment:
      - ENABLE_METRICS=true
    healthcheck:
      test: [ "CMD-SHELL", "wget -O - http://localhost:8081 &>/dev/null" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    depends_on:
      - grafana
    network_mode: "service:grafana"

  asf:
    container_name: asf
    image: ghcr.io/justarchinet/archisteamfarm:released
    command: --cryptkey-file /app/config/key
    environment:
      - TZ=Europe/Paris
    volumes:
      - /data/asf/config:/app/config
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.asf.rule=Host(`asf.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.asf.entrypoints=websecure"
      - "traefik.http.routers.asf.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.asf.middlewares=tailscaleAL"
    networks:
      - net-proxy

  steam-watcher:
    container_name: steam-watcher
    image: ghcr.io/lifeismana/steam-watcher:latest
    restart: unless-stopped
    environment:
      - TZ=Europe/Paris
    volumes:
      - /data/steam-watcher:/usr/src/app/config/
    networks:
      - net-proxy

  # myfeedcord:
  #   image: qolors/feedcord:latest # for amd64 architecture
  #   # image: qolors/feedcord:latest-arm64  # For arm64 architecture (Uncomment this line and comment the above if using arm64)
  #   container_name: feedcord
  #   restart: unless-stopped
  #   volumes:
  #     - /data/discord-rss/:/app/config/
  #   networks:
  #     - net-proxy

  rss-forwarder:
    image: ghcr.io/morphy2k/rss-forwarder:latest
    container_name: rss-forwarder
    restart: unless-stopped
    volumes:
      - /data/rss-forwarder:/data
    environment:
      - TZ=Europe/Paris
    networks:
      - net-proxy

  zipline:
    image: ghcr.io/diced/zipline:v4
    container_name: zipline
    restart: unless-stopped
    env_file:
      - env/zipline.env
    environment:
      - DATASOURCE_TYPE=s3
      - DATASOURCE_S3_BUCKET=zipline
      - DATASOURCE_S3_ENDPOINT=https://minio.${MAIN_DOMAIN}
      - DATASOURCE_S3_FORCE_PATH_STYLE=true
      - DATASOURCE_S3_REGION=eu-west-1
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.zipline.rule=Host(`${SECONDARY_DOMAIN}`)"
      - "traefik.http.routers.zipline.entrypoints=websecure"
      - "traefik.http.routers.zipline.tls.certresolver=cloudflare_main"
      - "traefik.http.services.zipline.loadbalancer.server.port=3000"
    networks:
      - net-postgres
      - net-proxy

  grist:
    image: gristlabs/grist:latest
    container_name: grist
    restart: unless-stopped
    volumes:
      - /data/grist:/persist
    env_file:
      - env/grist.env
    environment:
      - TZ=Europe/Paris
      - APP_HOME_URL=https://grist.${MAIN_DOMAIN}
      - GRIST_SANDBOX_FLAVOR=gvisor
      - TYPEORM_TYPE=postgres
      - TYPEORM_DATABASE=gristdb
      - TYPEORM_USERNAME=grist
      - TYPEORM_HOST=postgres
      - REDIS_URL=redis://redis:6379
      - GRIST_OIDC_IDP_ISSUER=https://authentik.${MAIN_DOMAIN}/application/o/grist/.well-known/openid-configuration
      #TODO: configure snapshots https://support.getgrist.com/self-managed/#how-do-i-set-up-snapshots
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.grist.rule=Host(`grist.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.grist.entrypoints=websecure"
      - "traefik.http.routers.grist.tls.certresolver=cloudflare_main"
    networks:
      - net-proxy
      - net-postgres
      - net-redis

  freshrss:
    image: freshrss/freshrss:1
    container_name: freshrss
    restart: unless-stopped
    env_file:
      - env/freshrss.env
    environment:
      - TZ=Europe/Paris
      - BASE_URL=freshrss.${MAIN_DOMAIN}
      - CRON_MIN=*/20
      - DB_TYPE=pgsql
      - DB_HOST=postgres
      - DB_USER=freshrss
      - DB_BASE=freshrssdb
      - TRUSTED_PROXIES=172.25.0.254
      - OIDC_ENABLED=1
      - OIDC_PROVIDER_METADATA_URL=https://authentik.${MAIN_DOMAIN}/application/o/freshrss/.well-known/openid-configuration
      - OIDC_X_FORWARDED_HEADERS=X-Forwarded-Proto X-Forwarded-Host
      - OIDC_SCOPES=openid profile email
    volumes:
      - /data/freshrss/data:/var/www/FreshRSS/data
      - /data/freshrss/extensions:/var/www/FreshRSS/extensions
    networks:
      - net-proxy
      - net-postgres
    labels:
      - "traefik.enable=true"
      - "traefik.http.middlewares.freshrss-compress.compress=true"
      - "traefik.http.middlewares.freshrss-headers.headers.browserXssFilter=true"
      - "traefik.http.middlewares.freshrss-headers.headers.frameDeny=true"
      - "traefik.http.middlewares.freshrss-headers.headers.referrerPolicy=no-referrer-when-downgrade"
      - "traefik.http.routers.freshrss.rule=Host(`freshrss.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.freshrss.entrypoints=websecure"
      - "traefik.http.routers.freshrss.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.freshrss.middlewares=crowdsec,freshrss-compress,freshrss-headers"

  couchdb:
    image: couchdb:3
    container_name: obsidian-livesync
    user: 1000:1000
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:5984/_up" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    env_file:
      - env/obsidian-livesync.env
    restart: unless-stopped
    volumes:
      - /data/obsidian-livesync/data:/opt/couchdb/data
      - /data/obsidian-livesync/local.ini:/opt/couchdb/etc/local.ini
    networks:
      - net-proxy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.obsidian-livesync.rule=Host(`obsidian-livesync.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.obsidian-livesync.entrypoints=websecure"
      - "traefik.http.routers.obsidian-livesync.tls.certresolver=cloudflare_main"
      - "traefik.http.services.obsidian-livesync.loadbalancer.server.port=5984"
      - "traefik.http.routers.obsidian-livesync.middlewares=tailscaleAL"
      - "traefik.http.middlewares.obsidiancors.headers.accesscontrolallowmethods=GET,PUT,POST,HEAD,DELETE"
      - "traefik.http.middlewares.obsidiancors.headers.accesscontrolallowheaders=accept,authorization,content-type,origin,referer"
      - "traefik.http.middlewares.obsidiancors.headers.accesscontrolalloworiginlist=app://obsidian.md,capacitor://localhost,http://localhost"
      - "traefik.http.middlewares.obsidiancors.headers.accesscontrolmaxage=3600"
      - "traefik.http.middlewares.obsidiancors.headers.addvaryheader=true"
      - "traefik.http.middlewares.obsidiancors.headers.accessControlAllowCredentials=true"

  stirling-pdf:
    container_name: stirling-pdf
    image: ghcr.io/stirling-tools/stirling-pdf:0.46.0-fat
    restart: unless-stopped
    healthcheck:
      #test: ["CMD-SHELL", "curl -f http://localhost:8080/api/v1/info/status | grep -q 'UP' && curl -fL http://localhost:8080/ | grep -qv 'Login via Single Sign-on'"]
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/api/v1/info/status | grep -q 'UP'" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s

    env_file:
      - env/stirling-pdf.env
    volumes:
      - /data/stirling-pdf/training-data:/usr/share/tessdata
      - /data/stirling-pdf/extra-configs:/configs
      - /data/stirling-pdf/custom-files:/customFiles
      - /data/stirling-pdf/logs:/logs
      - /data/stirling-pdf/pipeline:/pipeline
    environment:
      - DOCKER_ENABLE_SECURITY=true
      - SECURITY_ENABLELOGIN=true
      - SECURITY_OAUTH2_ENABLED=true
      - SECURITY_OAUTH2_AUTOCREATEUSER=true
      - SECURITY_OAUTH2_BLOCKREGISTRATION=false
      - SECURITY_OAUTH2_SCOPES=openid, profile, email
      - SECURITY_OAUTH2_USEASUSERNAME=email
      - SECURITY_OAUTH2_PROVIDER=authentik
      - SECURITY_LOGINMETHOD=oauth2
    networks:
      - net-proxy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.stirling-pdf.rule=Host(`stirling-pdf.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.stirling-pdf.entrypoints=websecure"
      - "traefik.http.routers.stirling-pdf.tls.certresolver=cloudflare_main"
      - "traefik.http.services.stirling-pdf.loadbalancer.server.port=8080"
      - "traefik.http.routers.stirling-pdf.middlewares=crowdsec"
    depends_on:
      traefik:
        condition: service_started
        restart: false
      authentik-server:
        condition: service_healthy
        restart: false

  it-tools:
    container_name: it-tools
    image: ghcr.io/corentinth/it-tools:latest
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:80" ]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - net-proxy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.it-tools.rule=Host(`it-tools.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.it-tools.entrypoints=websecure"
      - "traefik.http.routers.it-tools.tls.certresolver=cloudflare_main"

  mazanoke:
    container_name: mazanoke
    image: ghcr.io/civilblur/mazanoke:v1.1.4
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "wget -O - http://localhost:80 &>/dev/null" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - net-proxy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.mazanoke.rule=Host(`mazanoke.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.mazanoke.entrypoints=websecure"
      - "traefik.http.routers.mazanoke.tls.certresolver=cloudflare_main"

  excalidraw:
    container_name: excalidraw
    image: excalidraw/excalidraw:latest
    restart: unless-stopped
    networks:
      - net-proxy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.excalidraw.rule=Host(`excalidraw.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.excalidraw.entrypoints=websecure"
      - "traefik.http.routers.excalidraw.tls.certresolver=cloudflare_main"

  hedgedoc:
    container_name: hedgedoc
    image: quay.io/hedgedoc/hedgedoc:1.10.3
    restart: unless-stopped
    env_file:
      - env/hedgedoc.env
    environment:
      - CMD_DOMAIN=hedgedoc.${MAIN_DOMAIN}
      - CMD_PROTOCOL_USESSL=true
      - CMD_URL_ADDPORT=false
      - CMD_DB_HOST=postgres
      - CMD_DB_PORT=5432
      - CMD_DB_USERNAME=hedgedoc
      - CMD_DB_DATABASE=hedgedocdb
      - CMD_DB_DIALECT=postgres
      - CMD_EMAIL=false
      - CMD_ALLOW_EMAIL_REGISTER=false
      - CMD_OAUTH2_PROVIDERNAME=authentik
      - CMD_OAUTH2_SCOPE=openid profile email
      - CMD_OAUTH2_USER_PROFILE_URL=https://authentik.${MAIN_DOMAIN}/application/o/userinfo/
      - CMD_OAUTH2_TOKEN_URL=https://authentik.${MAIN_DOMAIN}/application/o/token/
      - CMD_OAUTH2_AUTHORIZATION_URL=https://authentik.${MAIN_DOMAIN}/application/o/authorize/
      - CMD_OAUTH2_USER_PROFILE_USERNAME_ATTR=preferred_username
      - CMD_OAUTH2_USER_PROFILE_DISPLAY_NAME_ATTR=name
      - CMD_OAUTH2_USER_PROFILE_EMAIL_ATTR=email
      - CMD_IMAGE_UPLOAD_TYPE=minio
      - CMD_S3_BUCKET=hedgedoc
      - CMD_MINIO_ENDPOINT=minio.${MAIN_DOMAIN}
      - CMD_MINIO_SECURE=true
    networks:
      - net-proxy
      - net-postgres
    labels:
      - traefik.enable=true
      - traefik.http.routers.hedgedoc.rule=Host(`hedgedoc.${MAIN_DOMAIN}`)
      - traefik.http.routers.hedgedoc.entrypoints=websecure
      - traefik.http.routers.hedgedoc.tls.certresolver=cloudflare_main

  minio:
    container_name: minio
    image: quay.io/minio/minio:latest
    restart: unless-stopped
    command: minio server /data --console-address ":9001"
    user: 1000:1000
    env_file:
      - env/minio.env
    environment:
      # not quite clear why minio doesn't like MINIO_DOMAIN with traefik
      - MINIO_ENABLE_COMPRESSION=on
      - MINIO_BROWSER_REDIRECT_URL=https://minio.internal.${MAIN_DOMAIN}
      - MINIO_IDENTITY_OPENID_CONFIG_URL=https://authentik.${MAIN_DOMAIN}/application/o/minio/.well-known/openid-configuration
      - MINIO_IDENTITY_OPENID_SCOPES=openid,profile,email,minio
    volumes:
      - /data/minio:/data
    networks:
      - net-proxy
      - net-postgres
      - net-prometheus
    healthcheck:
      test: [ "CMD", "mc", "ready", "local" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 15s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.minio.rule=Host(`minio.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.minio.entrypoints=websecure"
      - "traefik.http.routers.minio.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.minio.middlewares=crowdsec"
      - "traefik.http.routers.minio.service=minio"
      - "traefik.http.services.minio.loadbalancer.server.port=9000"
      - "traefik.http.routers.minio-console.rule=Host(`minio.internal.${MAIN_DOMAIN}`)"
      - "traefik.http.routers.minio-console.entrypoints=websecure"
      - "traefik.http.routers.minio-console.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.minio-console.middlewares=crowdsec"
      - "traefik.http.routers.minio-console.service=minio-console"
      - "traefik.http.services.minio-console.loadbalancer.server.port=9001"

  crowdsec:
    container_name: crowdsec
    image: ghcr.io/crowdsecurity/crowdsec:latest
    restart: always
    healthcheck:
      test: [ "CMD-SHELL", "cscli", "lapi status" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 15s
    environment:
      - COLLECTIONS=LePresidente/gitea crowdsecurity/traefik crowdsecurity/appsec-virtual-patching crowdsecurity/appsec-generic-rules crowdsecurity/sshd
      - CUSTOM_HOSTNAME=DockerMonster
      - BOUNCER_KEY_TraefikBouncer=${CROWDSEC_LAPI_KEY}
      - GID=1000
    volumes:
      - /data/crowdsec/acquis.yaml:/etc/crowdsec/acquis.yaml
      - /data/crowdsec/db:/var/lib/crowdsec/data
      - /data/crowdsec/config:/etc/crowdsec
      - logs-traefik:/var/log/traefik:ro
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - net-proxy
      - net-prometheus
    ports:
      # needed for the firewall bouncer
      - 127.0.0.1:8080:8080

  authentik-server:
    container_name: authentik-server
    image: ghcr.io/goauthentik/server:2025.4.0
    restart: unless-stopped
    command: server
    environment:
      AUTHENTIK_REDIS__HOST: redis
      AUTHENTIK_POSTGRESQL__HOST: postgres
      AUTHENTIK_POSTGRESQL__USER: authentik
      AUTHENTIK_POSTGRESQL__NAME: authentikdb
      AUTHENTIK_COOKIE_DOMAIN: ${MAIN_DOMAIN}
    env_file:
      - env/authentik.env
    volumes:
      - geoip:/geoip
    labels:
      - "traefik.enable=true"
      # arf est-ce que j'ai vraiment pas moyens de le restreindre mieux que Ã§a ?
      # && ! PathPrefix(`/if/admin/`)
      - "traefik.http.routers.authentik.rule=Host(`authentik.${MAIN_DOMAIN}`) || HostRegexp(`{subdomain:[a-z0-9-]+}.${MAIN_DOMAIN}`) && PathPrefix(`/outpost.goauthentik.io/`)"
      - "traefik.http.routers.authentik.entrypoints=websecure"
      - "traefik.http.routers.authentik.tls.certresolver=cloudflare_main"
      - "traefik.http.routers.authentik.service=authentik"
      - "traefik.http.routers.authentik.middlewares=crowdsec"
      - "traefik.http.services.authentik.loadbalancer.server.port=9000"
      - "traefik.http.middlewares.forwardAuth-authentik.forwardauth.address=https://authentik.${MAIN_DOMAIN}/outpost.goauthentik.io/auth/traefik"
      - "traefik.http.middlewares.forwardAuth-authentik.forwardauth.trustForwardHeader=true"
      - "traefik.http.middlewares.forwardAuth-authentik.forwardauth.authResponseHeaders=X-authentik-username,X-authentik-groups,X-authentik-email,X-authentik-name,X-authentik-uid,X-authentik-jwt,X-authentik-meta-jwks,X-authentik-meta-outpost,X-authentik-meta-provider,X-authentik-meta-app,X-authentik-meta-version"
      - homepage.group=Main
      - homepage.name=Authentik
      - homepage.icon=authentik.png
      - homepage.description=Authentik
      - homepage.href=https://authentik.${MAIN_DOMAIN}
      - homepage.widget.type=authentik
      - homepage.widget.url=https://authentik.${MAIN_DOMAIN}
      - homepage.widget.key=${AUTHENTIK_TOKEN}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - net-proxy
      - net-postgres
      - net-redis
      - net-prometheus

  authentik-worker:
    container_name: authentik-worker
    image: ghcr.io/goauthentik/server:2025.4.0
    restart: unless-stopped
    command: worker
    environment:
      AUTHENTIK_REDIS__HOST: redis
      AUTHENTIK_POSTGRESQL__HOST: postgres
      AUTHENTIK_POSTGRESQL__USER: authentik
      AUTHENTIK_POSTGRESQL__NAME: authentikdb
    env_file:
      - env/authentik.env
    volumes:
      - geoip:/geoip
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - net-proxy
      - net-postgres
      - net-redis

  geoipupdate:
    container_name: geoipupdate
    restart: unless-stopped
    image: ghcr.io/maxmind/geoipupdate:latest
    volumes:
      - "geoip:/usr/share/GeoIP"
    env_file:
      - env/geoipupdate.env
    environment:
      GEOIPUPDATE_EDITION_IDS: "GeoLite2-City GeoLite2-ASN GeoLite2-Country"
      GEOIPUPDATE_FREQUENCY: "8"

networks:
  net-proxy:
    name: net-proxy
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16
  net-postgres:
    name: net-postgres
    driver: bridge
    internal: true
  net-redis:
    name: net-redis
    driver: bridge
    internal: true
  net-influxdb:
    name: net-influxdb
    driver: bridge
    internal: true
  net-prometheus:
    name: net-prometheus
    driver: bridge
    internal: true

volumes:
  geoip:
    driver: local
  whatsupdocker:
  logs-traefik:
